name: Quality Gates

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  GO_VERSION: "1.23.0"
  COVERAGE_THRESHOLD: "80"
  PERFORMANCE_THRESHOLD: "10" # Max % performance regression

permissions:
  contents: read
  checks: write
  pull-requests: write

jobs:
  coverage-gate:
    name: Coverage Gate
    runs-on: ubuntu-latest
    outputs:
      coverage-percentage: ${{ steps.coverage.outputs.percentage }}
      coverage-status: ${{ steps.coverage.outputs.status }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go environment
        uses: ./.github/actions/setup-go

      - name: Setup test database
        run: |
          chmod +x ./test/docker/test-db.sh
          ./test/docker/test-db.sh start

      - name: Run tests with coverage
        run: |
          # Run unit tests
          go test -short -coverprofile=unit-coverage.out -covermode=atomic ./...

          # Run integration tests
          go test -coverprofile=integration-coverage.out -covermode=atomic ./internal/db

          # Combine coverage reports
          echo "mode: atomic" > combined-coverage.out
          grep -h -v "^mode:" unit-coverage.out integration-coverage.out | sort -u >> combined-coverage.out

      - name: Calculate coverage
        id: coverage
        run: |
          COVERAGE=$(go tool cover -func=combined-coverage.out | grep total | awk '{print $3}' | sed 's/%//')
          echo "percentage=$COVERAGE" >> "$GITHUB_OUTPUT"

          if (( $(echo "$COVERAGE >= $COVERAGE_THRESHOLD" | bc -l) )); then
            echo "status=pass" >> "$GITHUB_OUTPUT"
            echo "✅ Coverage: $COVERAGE% (threshold: $COVERAGE_THRESHOLD%)"
          else
            echo "status=fail" >> "$GITHUB_OUTPUT"
            echo "❌ Coverage: $COVERAGE% below threshold: $COVERAGE_THRESHOLD%"
            exit 1
          fi

      - name: Generate coverage report
        run: |
          go tool cover -html=combined-coverage.out -o coverage-report.html

          # Generate coverage badge
          COVERAGE="${{ steps.coverage.outputs.percentage }}"
          COLOR="red"
          if (( $(echo "$COVERAGE >= 90" | bc -l) )); then
            COLOR="brightgreen"
          elif (( $(echo "$COVERAGE >= 80" | bc -l) )); then
            COLOR="yellow"
          elif (( $(echo "$COVERAGE >= 70" | bc -l) )); then
            COLOR="orange"
          fi

          curl -s "https://img.shields.io/badge/coverage-${COVERAGE}%25-${COLOR}" > coverage-badge.svg

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            coverage-report.html
            combined-coverage.out
            coverage-badge.svg

      - name: Comment coverage on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const coverage = '${{ steps.coverage.outputs.percentage }}';
            const threshold = '${{ env.COVERAGE_THRESHOLD }}';
            const status = '${{ steps.coverage.outputs.status }}';
            const icon = status === 'pass' ? '✅' : '❌';

            const comment = `## ${icon} Coverage Report

            **Current Coverage:** ${coverage}%
            **Threshold:** ${threshold}%
            **Status:** ${status.toUpperCase()}

            [View detailed coverage report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Cleanup test database
        if: always()
        run: ./test/docker/test-db.sh cleanup

  performance-gate:
    name: Performance Gate
    runs-on: ubuntu-latest
    outputs:
      performance-status: ${{ steps.benchmark.outputs.status }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go environment
        uses: ./.github/actions/setup-go

      - name: Setup test database
        run: |
          chmod +x ./test/docker/test-db.sh
          ./test/docker/test-db.sh start

      - name: Run performance benchmarks
        id: benchmark
        run: |
          # Run benchmarks and save results
          go test -bench=. -benchmem -count=3 -timeout=10m ./internal/db > current-benchmarks.txt

          # Create baseline if it doesn't exist (for new PRs)
          if [ ! -f benchmark-baseline.txt ]; then
            cp current-benchmarks.txt benchmark-baseline.txt
            echo "status=baseline-created" >> "$GITHUB_OUTPUT"
            echo "📊 Baseline benchmarks created"
            exit 0
          fi

          # Compare with baseline (simplified check)
          echo "status=pass" >> "$GITHUB_OUTPUT"
          echo "✅ Performance benchmarks completed"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: current-benchmarks.txt

      - name: Cleanup test database
        if: always()
        run: ./test/docker/test-db.sh cleanup

  code-quality-gate:
    name: Code Quality Gate
    runs-on: ubuntu-latest
    outputs:
      quality-score: ${{ steps.quality.outputs.score }}
      quality-status: ${{ steps.quality.outputs.status }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Go environment
        uses: ./.github/actions/setup-go

      - name: Run gocyclo (complexity check)
        run: |
          go install github.com/fzipp/gocyclo/cmd/gocyclo@latest
          gocyclo -over 15 . | tee complexity-report.txt
          COMPLEX_FUNCS=$(wc -l < complexity-report.txt)
          echo "Complex functions (>15): $COMPLEX_FUNCS"

      - name: Run ineffassign
        run: |
          go install github.com/gordonklaus/ineffassign@latest
          ineffassign ./... | tee ineffassign-report.txt
          INEFFASSIGN_COUNT=$(wc -l < ineffassign-report.txt)
          echo "Ineffective assignments: $INEFFASSIGN_COUNT"

      - name: Run misspell
        run: |
          go install github.com/client9/misspell/cmd/misspell@latest
          misspell -error . | tee misspell-report.txt
          MISSPELL_COUNT=$(wc -l < misspell-report.txt)
          echo "Misspellings: $MISSPELL_COUNT"

      - name: Calculate quality score
        id: quality
        run: |
          COMPLEX_FUNCS=$(wc -l < complexity-report.txt)
          INEFFASSIGN_COUNT=$(wc -l < ineffassign-report.txt)
          MISSPELL_COUNT=$(wc -l < misspell-report.txt)

          # Simple scoring: start with 100, deduct points for issues
          SCORE=100
          SCORE=$((SCORE - COMPLEX_FUNCS * 5))
          SCORE=$((SCORE - INEFFASSIGN_COUNT * 2))
          SCORE=$((SCORE - MISSPELL_COUNT * 1))

          # Ensure score doesn't go below 0
          if [ $SCORE -lt 0 ]; then
            SCORE=0
          fi

          echo "score=$SCORE" >> "$GITHUB_OUTPUT"

          if [ $SCORE -ge 80 ]; then
            echo "status=pass" >> "$GITHUB_OUTPUT"
            echo "✅ Code Quality Score: $SCORE/100"
          else
            echo "status=fail" >> "$GITHUB_OUTPUT"
            echo "❌ Code Quality Score: $SCORE/100 (minimum: 80)"
            exit 1
          fi

      - name: Upload quality reports
        uses: actions/upload-artifact@v4
        with:
          name: quality-reports
          path: |
            complexity-report.txt
            ineffassign-report.txt
            misspell-report.txt

  binary-size-gate:
    name: Binary Size Gate
    runs-on: ubuntu-latest
    outputs:
      binary-size: ${{ steps.size.outputs.size }}
      size-status: ${{ steps.size.outputs.status }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go environment
        uses: ./.github/actions/setup-go

      - name: Build optimized binary
        run: |
          make build

          # Also build with optimizations
          go build -ldflags="-s -w" -o build/scanorama-optimized ./cmd/scanorama

      - name: Check binary size
        id: size
        run: |
          SIZE=$(stat -c%s build/scanorama)
          SIZE_MB=$((SIZE / 1024 / 1024))
          OPTIMIZED_SIZE=$(stat -c%s build/scanorama-optimized)
          OPTIMIZED_SIZE_MB=$((OPTIMIZED_SIZE / 1024 / 1024))

          echo "size=$SIZE" >> "$GITHUB_OUTPUT"

          # Fail if binary is over 50MB
          if [ $SIZE_MB -gt 50 ]; then
            echo "status=fail" >> "$GITHUB_OUTPUT"
            echo "❌ Binary size: ${SIZE_MB}MB exceeds 50MB limit"
            exit 1
          else
            echo "status=pass" >> "$GITHUB_OUTPUT"
            echo "✅ Binary size: ${SIZE_MB}MB (optimized: ${OPTIMIZED_SIZE_MB}MB)"
          fi

          # Create size report
          echo "# Binary Size Report" > size-report.md
          echo "- **Standard build**: ${SIZE_MB}MB" >> size-report.md
          echo "- **Optimized build**: ${OPTIMIZED_SIZE_MB}MB" >> size-report.md
          echo "- **Size limit**: 50MB" >> size-report.md

      - name: Upload size report
        uses: actions/upload-artifact@v4
        with:
          name: size-report
          path: |
            size-report.md
            build/scanorama
            build/scanorama-optimized

  security-gate:
    name: Security Gate
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
    outputs:
      security-status: ${{ steps.security.outputs.status }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go environment
        uses: ./.github/actions/setup-go
        with:
          install-system-deps: "false"

      - name: Run govulncheck
        id: security
        run: |
          go install golang.org/x/vuln/cmd/govulncheck@latest

          if govulncheck ./...; then
            echo "status=pass" >> "$GITHUB_OUTPUT"
            echo "✅ No known vulnerabilities found"
          else
            echo "status=fail" >> "$GITHUB_OUTPUT"
            echo "❌ Vulnerabilities detected"
            exit 1
          fi

  quality-summary:
    name: Quality Summary
    runs-on: ubuntu-latest
    needs: [coverage-gate, performance-gate, code-quality-gate, binary-size-gate, security-gate]
    if: always()
    permissions:
      contents: read
      checks: write
      pull-requests: write
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: quality-artifacts

      - name: Generate quality dashboard
        run: |
          echo "# 📊 Quality Dashboard" > quality-dashboard.md
          echo "" >> quality-dashboard.md

          # Coverage
          COVERAGE="${{ needs.coverage-gate.outputs.coverage-percentage }}"
          COVERAGE_STATUS="${{ needs.coverage-gate.outputs.coverage-status }}"
          COVERAGE_ICON=$([ "$COVERAGE_STATUS" = "pass" ] && echo "✅" || echo "❌")
          echo "## ${COVERAGE_ICON} Test Coverage: ${COVERAGE}%" >> quality-dashboard.md
          echo "" >> quality-dashboard.md

          # Performance
          PERF_STATUS="${{ needs.performance-gate.outputs.performance-status }}"
          PERF_ICON=$([ "$PERF_STATUS" = "pass" ] && echo "✅" || echo "📊")
          echo "## ${PERF_ICON} Performance: ${PERF_STATUS}" >> quality-dashboard.md
          echo "" >> quality-dashboard.md

          # Code Quality
          QUALITY_SCORE="${{ needs.code-quality-gate.outputs.quality-score }}"
          QUALITY_STATUS="${{ needs.code-quality-gate.outputs.quality-status }}"
          QUALITY_ICON=$([ "$QUALITY_STATUS" = "pass" ] && echo "✅" || echo "❌")
          echo "## ${QUALITY_ICON} Code Quality: ${QUALITY_SCORE}/100" >> quality-dashboard.md
          echo "" >> quality-dashboard.md

          # Binary Size
          BINARY_SIZE="${{ needs.binary-size-gate.outputs.binary-size }}"
          SIZE_STATUS="${{ needs.binary-size-gate.outputs.size-status }}"
          SIZE_ICON=$([ "$SIZE_STATUS" = "pass" ] && echo "✅" || echo "❌")
          SIZE_MB=$((BINARY_SIZE / 1024 / 1024))
          echo "## ${SIZE_ICON} Binary Size: ${SIZE_MB}MB" >> quality-dashboard.md
          echo "" >> quality-dashboard.md

          # Security
          SECURITY_STATUS="${{ needs.security-gate.outputs.security-status }}"
          SECURITY_ICON=$([ "$SECURITY_STATUS" = "pass" ] && echo "✅" || echo "❌")
          echo "## ${SECURITY_ICON} Security: ${SECURITY_STATUS}" >> quality-dashboard.md
          echo "" >> quality-dashboard.md

          echo "---" >> quality-dashboard.md
          echo "Generated on: $(date -u)" >> quality-dashboard.md

      - name: Create check run
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const dashboard = fs.readFileSync('quality-dashboard.md', 'utf8');

            const coverage = '${{ needs.coverage-gate.outputs.coverage-status }}';
            const quality = '${{ needs.code-quality-gate.outputs.quality-status }}';
            const security = '${{ needs.security-gate.outputs.security-status }}';
            const size = '${{ needs.binary-size-gate.outputs.size-status }}';

            const allPassed = [coverage, quality, security, size].every(status =>
              status === 'pass' || status === 'baseline-created'
            );

            await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'Quality Gates',
              head_sha: context.sha,
              status: 'completed',
              conclusion: allPassed ? 'success' : 'failure',
              output: {
                title: allPassed ? '✅ All Quality Gates Passed' : '❌ Quality Gates Failed',
                summary: dashboard
              }
            });

      - name: Comment quality summary on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const dashboard = fs.readFileSync('quality-dashboard.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: dashboard
            });

      - name: Upload quality dashboard
        uses: actions/upload-artifact@v4
        with:
          name: quality-dashboard
          path: |
            quality-dashboard.md
            quality-artifacts/
